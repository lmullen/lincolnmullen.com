<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title>Text Analysis for Historians</title>
  <style type="text/css">
    code {
      white-space: pre;
    }

  </style>
  <link rel="stylesheet" href="tufte.css" type="text/css" />
  <link rel="stylesheet" href="custom.css" type="text/css" />
  <script defer data-domain="lincolnmullen.com" src="https://plausible.io/js/plausible.js"></script>
</head>

<body>
  <div id="header">
    <h1 class="title">Text Analysis for Historians</h1>
  </div>
  <p><a href="#schedule">Schedule</a> | <a href="#assignments-and-expectations">Assignments</a> | <a
      href="#acknowledgments-and-fine-print">Fine Print</a> | <a href="#references">References</a></p>
  <p class="sans">
    Independent study, fall 2016. <a href="http://historyarthistory.gmu.edu/">Department of History and Art History</a>,
    George Mason University. Meets every other Wednesday at 1 p.m. for discussion; work sessions on alternate weeks as
    necessary. Instructor: <a href="http://lincolnmullen.com">Lincoln Mullen</a> &lt;<a
      href="mailto:lmullen@gmu.edu">lmullen@gmu.edu</a>&gt;. Office: Research Hall 457.
  </p>
  <p>This independent study is an advanced course in the theory and practice of text analysis for historians. You will
    read current research in digital history and cognate fields. The aim is to learn the methods of text analysis which
    are most likely to produce insights useful for historical interpretation. You will work primarily in the <a
      href="https://www.r-project.org/">R programming language</a> and with common Unix-style utilities, performing an
    analysis using each method we discuss week by week. By the end of the semester, you will write a paper which uses
    text analysis of a corpus to make a historical argument or interpretation.</p>
  <h2 id="schedule">Schedule</h2>
  <h3 id="week-1-august-31-introduction">Week 1 (August 31): Introduction</h3>
  <ul>
    <li><span class="citation">Matthew K. Gold et al., “Forum: Text Analysis at Scale,” in <em>Debates in the Digital
          Humanities 2016</em> (University of Minnesota Press, 2016), 525–568, <a
          href="http://dhdebates.gc.cuny.edu/debates/text/93"
          class="uri">http://dhdebates.gc.cuny.edu/debates/text/93</a>.</span></li>
    <li><span class="citation">Stephen Robertson, “The Differences Between Digital Humanities and Digital History,” in
        <em>Debates in the Digital Humanities 2016</em>, ed. Matthew K. Gold and Lauren F. Klein (University of
        Minnesota Press, 2016), 289–307, <a href="http://dhdebates.gc.cuny.edu/debates/text/76"
          class="uri">http://dhdebates.gc.cuny.edu/debates/text/76</a>.</span></li>
    <li><span class="citation">Dan Cohen, “Searching for the Victorians,” October 4, 2010, <a
          href="http://www.dancohen.org/2010/10/04/searching-for-the-victorians/"
          class="uri">http://www.dancohen.org/2010/10/04/searching-for-the-victorians/</a>.</span></li>
    <li><span class="citation">Ted Underwood, “Seven Ways Humanists Are Using Computers to Understand Text. The Stone
        and the Shell,” June 4, 2015, <a
          href="https://tedunderwood.com/2015/06/04/seven-ways-humanists-are-using-computers-to-understand-text/"
          class="uri">https://tedunderwood.com/2015/06/04/seven-ways-humanists-are-using-computers-to-understand-text/</a>.</span>
    </li>
    <li><span class="citation">Matthew L. Jockers, <em>Text Analysis with R for Students of Literature</em> (Springer,
        2014), <a href="http://link.springer.com/10.1007/978-3-319-03164-4"
          class="uri">http://link.springer.com/10.1007/978-3-319-03164-4</a>, chs. 1–2.</span></li>
    <li><span class="citation">Taylor Arnold and Lauren Tilton, <em>Humanities Data in R</em> (Springer, 2015), <a
          href="http://link.springer.com/10.1007/978-3-319-20702-5"
          class="uri">http://link.springer.com/10.1007/978-3-319-20702-5</a>, chs. 1–2.</span></li>
  </ul>
  <p>Practicum: Before our first meeting, install <a href="https://www.r-project.org/">R</a> and the <a
      href="https://www.rstudio.com/products/rstudio/#Desktop">RStudio Desktop IDE</a> (you may wish to install the <a
      href="https://www.rstudio.com/products/rstudio/download/preview/">preview version</a> to get notebook support).
    Start to become familiar with the basics of R as described in the introductory chapters of either Jockers or Arnold
    and Tilton. You should also become start to become familiar with the basics of the Unix-style command line (see
    Shotts, <em>Linux Command Line</em>, as a reference).</p>
  <h3 id="week-2-september-7-working-with-corpus-metadata">Week 2 (September 7): Working with corpus metadata</h3>
  <ul>
    <li><span class="citation">Stephen Robertson, “Searching for Anglo-American Digital Legal History,” <em>Law and
          History Review</em> 34, no. 4 (August 2016), doi:<a
          href="https://doi.org/10.1017/S0738248016000389">10.1017/S0738248016000389</a>.</span></li>
    <li><span class="citation">Tim Hitchcock and William J. Turkel, “The Old Bailey Proceedings, 1674–1913: Text Mining
        for Evidence of Court Behavior,” <em>Law and History Review</em> 34, no. 4 (August 2016): 1–27, doi:<a
          href="https://doi.org/10.1017/S0738248016000304">10.1017/S0738248016000304</a>.</span></li>
    <li><span class="citation">Benjamin Schmidt, “Women in the Libraries. Sapping Attention,” May 8, 2012, <a
          href="http://sappingattention.blogspot.com/2012/05/women-in-libraries.html"
          class="uri">http://sappingattention.blogspot.com/2012/05/women-in-libraries.html</a>.</span></li>
    <li><span class="citation">Julia Flanders and Fotis Jannidis, “Data Modeling,” in <em>A New Companion to the Digital
          Humanities</em>, ed. Susan Schreibman, Ray Siemens, and John Unsworth (Wiley Blackwell, 2016), 229–37.</span>
    </li>
    <li><span class="citation">Stéfan Sinclair and Geoffrey Rockwell, “Text Analysis and Visualization: Making Meaning
        Count,” in <em>A New Companion to the Digital Humanities</em>, ed. Susan Schreibman, Ray Siemens, and John
        Unsworth (Wiley Blackwell, 2016), 274–90.</span></li>
  </ul>
  <p>Practicum: Download at least one of the provided corpora. Extract the metadata into tables. Do an exploratory data
    analysis of the corpus metadata, paying special attention to the question of which texts actually belong in the
    corpus. See the <a href="http://rmarkdown.rstudio.com/">R Markdown documentation</a> for help getting started with
    your first notebook. See Jenny Bryan, <a href="http://happygitwithr.com/"><em>Happy Git and GitHub for the
        useR</em></a>, for guidance using Git/GitHub.</p>
  <h3 id="week-3-september-21-vector-space-models">Week 3 (September 21): Vector space models</h3>
  <ul>
    <li><span class="citation">A. W. B. Simpson, “The Rise and Fall of the Legal Treatise: Legal Principles and the
        Forms of Legal Literature,” <em>The University of Chicago Law Review</em> 48, no. 3 (1981): 632–679, doi:<a
          href="https://doi.org/10.2307/1599330">10.2307/1599330</a>.</span></li>
    <li><span class="citation">Shawn Graham, Ian Milligan, and Scott Weingart, <em>Exploring Big Historical Data: The
          Historian’s Macroscope</em> (Imperial College Press, 2015), ch. 3.</span></li>
    <li><span class="citation">Arnold and Tilton, <em>Humanities Data in R</em>, chs. 9-10.</span></li>
    <li><span class="citation">Michael Witmore, “Text: A Massively Addressable Object,” in <em>Debates in the Digital
          Humanities 2012</em> (University of Minnesota Press, 2012), <a
          href="http://dhdebates.gc.cuny.edu/debates/text/28"
          class="uri">http://dhdebates.gc.cuny.edu/debates/text/28</a>.</span></li>
    <li><span class="citation">Benjamin Schmidt, “Age Cohort and Vocabulary Use. Sapping Attention,” April 11, 2011, <a
          href="http://sappingattention.blogspot.com/2011/04/age-cohort-and-vocabulary-use.html"
          class="uri">http://sappingattention.blogspot.com/2011/04/age-cohort-and-vocabulary-use.html</a>.</span></li>
    <li><span class="citation">Jure Leskovec, Anand Rajaraman, and Jeff Ullman, <em>Mining of Massive Datasets</em>, 2nd
        ed. (Cambridge University Press, 2014), <a href="http://www.mmds.org/" class="uri">http://www.mmds.org/</a>,
        ch. 1.</span></li>
  </ul>
  <p>Practicum: Using <a href="https://cran.rstudio.com/web/packages/text2vec/">text2vec</a>, create a document-term
    model of a corpus. Experiment with using words and n-grams, filtering terms and stemming, applying transformations
    such as TF-IDF, and applying distance measures such as cosine distance. Produce plots of how terms are used. (You
    may want to work ahead on unsupervised clustering or principal component analysis.)</p>
  <h3 id="week-4-october-5-clustering-and-classification">Week 4 (October 5): Clustering and classification</h3>
  <ul>
    <li><span class="citation">Lawrence M. Friedman, <em>A History of American Law</em>, 2nd ed. (New York: Simon &amp;
        Schuster, 1985), pt. 2.</span></li>
    <li><span class="citation">Jockers, <em>Text Analysis</em>, chs. 11–12.</span></li>
    <li><span class="citation">Matthew L. Jockers and Ted Underwood, “Text-Mining the Humanities,” in <em>A New
          Companion to the Digital Humanities</em>, ed. Susan Schreibman, Ray Siemens, and John Unsworth (Wiley
        Blackwell, 2016), 291–306.</span></li>
    <li><span class="citation">D. Sculley and Bradley M. Pasanek, “Meaning and Mining: The Impact of Implicit
        Assumptions in Data Mining for the Humanities,” <em>Literary and Linguistic Computing</em> 23, no. 4 (2008):
        409–424, <a href="http://llc.oxfordjournals.org/content/23/4/409.short"
          class="uri">http://llc.oxfordjournals.org/content/23/4/409.short</a>.</span></li>
    <li><span class="citation">Leskovec, Rajaraman, and Ullman, <em>Mining of Massive Datasets</em>, ch. 7.</span></li>
    <li><span class="citation">Gareth James et al., <em>An Introduction to Statistical Learning with Applications in
          R</em> (Springer, 2013), chs. 2, 3, 10.</span></li>
  </ul>
  <p>Practicum: Try a variety of unsupervised classification methods (e.g., K-means) and dimensionality reduction
    methods (e.g., PCA) if you did not do so last week. Using the <a
      href="http://topepo.github.io/caret/index.html">caret package</a> make a supervised classifier (using various
    machine learning methods) to predict some aspect of your text. You should use the corpus metadata for your
    classification labels.</p>
  <h3 id="week-5-october-19-text-reuse">Week 5 (October 19): Text reuse</h3>
  <ul>
    <li><span class="citation">Friedman, <em>A History of American Law</em>, pt. 3.</span></li>
    <li><span class="citation">Ryan Cordell, “Reprinting, Circulation, and the Network Author in Antebellum Newspapers,”
        <em>American Literary History</em> 27, no. 3 (September 1, 2015): 417–445, doi:<a
          href="https://doi.org/10.1093/alh/ajv028">10.1093/alh/ajv028</a>.</span></li>
    <li><span class="citation">David A. Smith, Ryan Cordell, and Abby Mullen, “Computational Methods for Uncovering
        Reprinted Texts in Antebellum Newspapers,” <em>American Literary History</em> 27, no. 3 (September 1, 2015):
        E1–E15, doi:<a href="https://doi.org/10.1093/alh/ajv029">10.1093/alh/ajv029</a>.</span></li>
    <li><span class="citation">David A. Smith et al., “Detecting and Modeling Local Text Reuse,” in <em>Proceedings of
          the 14th ACM/IEEE-CS Joint Conference on Digital Libraries</em> (IEEE Press, 2014), 183–192, <a
          href="http://dl.acm.org/citation.cfm?id=2740800"
          class="uri">http://dl.acm.org/citation.cfm?id=2740800</a>.</span></li>
    <li><span class="citation">Leskovec, Rajaraman, and Ullman, <em>Mining of Massive Datasets</em>, ch. 3.</span></li>
    <li>Kellen Funk and Lincoln Mullen, “The Spine of American Law: Digital Text Analysis and U.S. Legal Practice.” See
      also our <a
        href="http://lmullen.github.io/civil-procedure-codes/talks/dh-working-group/Funk-Mullen.Migration-Field-Code.working-paper.pdf">working
        paper</a> and the <a href="http://lmullen.github.io/civil-procedure-codes/">notebooks</a> for the project.</li>
  </ul>
  <p>Practicum: Using either the <a href="https://github.com/ropensci/textreuse">textreuse</a> or <a
      href="https://github.com/dselivanov/lshr">LSHR</a> packages, look for reused passages in the corpus you are
    working with. Create clusters or networks of those reuses.</p>
  <h3 id="week-6-november-2-topic-modeling">Week 6 (November 2): Topic modeling</h3>
  <ul>
    <li><span class="citation">Michael H. Hoeflich, <em>Legal Publishing in Antebellum America</em> (New York: Cambridge
        University Press, 2010), chs. 2, 3, 7.</span></li>
    <li><em>Journal of Digital Humanities</em> 2, no. 1 (winter 2012): <a
        href="http://journalofdigitalhumanities.org/2-1/" class="uri">http://journalofdigitalhumanities.org/2-1/</a>.
    </li>
    <li><span class="citation">Robert K. Nelson and Digital Scholarship Lab, University of Richmond, “Mining the
        Dispatch,” 2011, <a href="http://dsl.richmond.edu/dispatch/"
          class="uri">http://dsl.richmond.edu/dispatch/</a>.</span></li>
    <li><span class="citation">David J. Newman and Sharon Block, “Probabilistic Topic Decomposition of an
        Eighteenth-Century American Newspaper,” <em>Journal of the American Society for Information Science and
          Technology</em> 57, no. 6 (2006): 753–767, <a href="http://onlinelibrary.wiley.com/doi/10.1002/asi.20342/full"
          class="uri">http://onlinelibrary.wiley.com/doi/10.1002/asi.20342/full</a>.</span></li>
    <li><span class="citation">Graham, Milligan, and Weingart, <em>Exploring Big Historical Data</em>, ch. 4.</span>
    </li>
    <li><span class="citation">Jockers, <em>Text Analysis</em>, ch. 13.</span></li>
  </ul>
  <p>Practicum: Using the <a href="https://github.com/TommyJones/textmineR">textmineR</a>, create topic models of the
    corpus that you are working with. Make plots of changes in topics over time.</p>
  <h3 id="week-7-november-16-word-embedded-models">Week 7 (November 16): Word-embedded models</h3>
  <ul>
    <li><span class="citation">Barbara Young Welke, <em>Law and the Borders of Belonging in the Long Nineteenth Century
          United States</em> (Cambridge University Press, 2010), 1–94.</span></li>
    <li><span class="citation">Benjamin Schmidt, “Vector Space Models for the Digital Humanities,” October 25, 2015, <a
          href="http://bookworm.benschmidt.org/posts/2015-10-25-Word-Embeddings.html"
          class="uri">http://bookworm.benschmidt.org/posts/2015-10-25-Word-Embeddings.html</a>.</span></li>
    <li><span class="citation">Benjamin Schmidt, “Rejecting the Gender Binary: A Vector-Space Operation,” October 30,
        2015, <a href="http://bookworm.benschmidt.org/posts/2015-10-30-rejecting-the-gender-binary.html"
          class="uri">http://bookworm.benschmidt.org/posts/2015-10-30-rejecting-the-gender-binary.html</a>.</span></li>
    <li><span class="citation">Michael A. Gavin, “The Arithmetic of Concepts: A Response to Peter de Bolla. Modeling
        Literary History,” September 18, 2015, <a
          href="http://modelingliteraryhistory.org/2015/09/18/the-arithmetic-of-concepts-a-response-to-peter-de-bolla/"
          class="uri">http://modelingliteraryhistory.org/2015/09/18/the-arithmetic-of-concepts-a-response-to-peter-de-bolla/</a>.</span>
    </li>
    <li><span class="citation">T. Mikolov and J. Dean, “Distributed Representations of Words and Phrases and Their
        Compositionality,” <em>Advances in Neural Information Processing Systems</em> (2013), <a
          href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf"
          class="uri">https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf</a>.</span>
    </li>
    <li><span class="citation">Jeffrey Pennington, Richard Socher, and Christopher D. Manning, “Glove: Global Vectors
        for Word Representation.” in <em>EMNLP</em>, vol. 14, 2014, 1532–43, <a
          href="http://nlp.stanford.edu/pubs/glove.pdf" class="uri">http://nlp.stanford.edu/pubs/glove.pdf</a>.</span>
    </li>
    <li><span class="citation">Matt J. Kusner et al., “From Word Embeddings to Document Distances,” in <em>Proceedings
          of the 32nd International Conference on Machine Learning (ICML 2015)</em>, 2015, 957–966, <a
          href="http://www.jmlr.org/proceedings/papers/v37/kusnerb15.pdf"
          class="uri">http://www.jmlr.org/proceedings/papers/v37/kusnerb15.pdf</a>.</span></li>
    <li>GloVe vignette from <a href="https://cran.rstudio.com/web/packages/text2vec/">text2vec</a> and <a
        href="https://github.com/bmschmidt/wordVectors">wordVectors</a> documentation.</li>
  </ul>
  <p>Practicum: Train a word-embedded model on your corpus, or train several models on chronological or thematic subsets
    of your corpus. Use the model(s) to find distinctive use of language. More ambitious: use some of the more
    cutting-edge algorithms that use word vectors as inputs, for example, for finding document distances.</p>
  <h3 id="week-8-november-30-named-entity-recognition">Week 8 (November 30): Named-entity recognition</h3>
  <ul>
    <li><span class="citation">Welke, <em>Law and the Borders of Belonging</em>, 95–158.</span></li>
    <li><span class="citation">Cameron Blevins, “Space, Nation, and the Triumph of Region: A View of the World from
        Houston,” <em>Journal of American History</em> 101, no. 1 (June 1, 2014): 122–147, doi:<a
          href="https://doi.org/10.1093/jahist/jau184">10.1093/jahist/jau184</a>.</span></li>
    <li><span class="citation">Benjamin Schmidt and Mitch Fraas, “The Language of the State of the Union,” <em>The
          Atlantic</em> (January 18, 2015), <a
          href="http://www.theatlantic.com/politics/archive/2015/01/the-language-of-the-state-of-the-union/384575/"
          class="uri">http://www.theatlantic.com/politics/archive/2015/01/the-language-of-the-state-of-the-union/384575/</a>.</span>
    </li>
    <li><span class="citation">Mitch Fraas and Benjamin Schmidt, “Mapping the State of the Union,” <em>The Atlantic</em>
        (January 18, 2015), <a
          href="http://www.theatlantic.com/politics/archive/2015/01/mapping-the-state-of-the-union/384576/"
          class="uri">http://www.theatlantic.com/politics/archive/2015/01/mapping-the-state-of-the-union/384576/</a>.</span>
    </li>
  </ul>
  <p>Practicum: Using the <a href="https://cran.rstudio.com/web/packages/openNLP/">openNLP</a> or <a
      href="https://cran.rstudio.com/web/packages/coreNLP/">coreNLP</a> packages, run named-entity recognition on your
    corpus. Plot the entities over time or space.</p>
  <h2 id="assignments-and-expectations">Assignments and expectations</h2>
  <p>You are encouraged to work with the <a
      href="http://gdc.gale.com/products/the-making-of-modern-law-legal-treatises-1800-1926/acquire/faqs/"><em>Making of
        Modern Law: Legal Treatises</em></a> corpus, which the library will provide. Alternatives include <a
      href="http://chroniclingamerica.loc.gov/"><em>Chronicling America</em></a>, <a
      href="http://www.gale.com/19th-century-us-newspapers/"><em>19th Century U.S. Newspapers</em></a>, and the <a
      href="https://github.com/lmullen/WPAnarratives">WPA former slave narratives</a>. You may substitute another corpus
    after consulting with me.</p>
  <p>Come prepared to discuss the readings assigned for each meeting. There are several kinds of reading. Works on legal
    history set the stage for the corpus we are investigating, so that you know what questions are worth asking. If you
    decide to work on a corpus other than MOML, plan on substituting your own readings for works in that category. Works
    on other historical subjects demonstrate how the methods we are studying can be applied to historical or literary
    historical questions. The methodological pieces, well, explain how the methods work. Don’t get hung up on the
    details of implementation: read to understand what the transformation is that the method accomplishes. Some of the
    methodological pieces are more practical, while others provide the theoretical basis. There is much more to read
    than I can assign, but the references below (also in a <a
      href="https://www.zotero.org/groups/text_analysis_for_historians">Zotero group library</a>) contain many
    additional works.</p>
  <p>Before each meeting, you will create an <a href="http://rmarkdown.rstudio.com/r_notebooks.html">R Markdown
      notebook</a> which—in prose, code, and figures—explores your chosen corpus of texts using the specified
    methodology. Get as far as you can with each method. You are always welcome to share code and ideas with other
    people in the class, though each person must turn in his or her own notebook. Submit all of the notebooks for the
    semester in a single GitHub repository. Name each notebook something sensible, like
    <code>08-named-entity-recognition.nb.html</code>.</p>
  <p>At the end of the semester, you will write a conference paper which makes a historical argument on the basis of the
    corpus you have chosen. Submit these papers as a separate GitHub repository. Prepare a one-page proposal by week 4,
    share a one-page statement of progress and problems by week 7, and submit the draft by 5 p.m. on December 16.</p>
  <p>Grades will be assigned with 50% of the weight given to completing the readings and notebooks, and 50% to the final
    paper.</p>
  <h1 id="acknowledgments-and-fine-print">Acknowledgments and fine print</h1>
  <p>I have benefited from syllabi by <a href="https://tedunderwood.com/2015/01/16/syllabus-for-a-graduate-seminar/">Ted
      Underwood</a>, <a href="http://www.rci.rutgers.edu/~ag978/litdata/">Andrew Goldstone</a>, and <a
      href="http://benschmidt.org/HDA15/">Ben Schmidt</a>. <a href="http://kellenfunk.org/">Kellen Funk</a> provided
    advice about legal history readings.</p>
  <p>See the <a href="http://catalog.gmu.edu/">George Mason University catalog</a> for general policies, as well as the
    university <a href="http://ctfe.gmu.edu/professional-development/mason-diversity-statement/">statement on
      diversity</a>. You are expected to know and follow George Mason’s policies on <a
      href="http://oai.gmu.edu/">academic integrity</a> and the <a
      href="http://oai.gmu.edu/understanding-the-honor-code/">honor code</a>. If you are a student with a disability and
    you need academic accommodations, please see me and contact the Office of Disability Services at 703-993-2474 or
    through <a href="http://ods.gmu.edu">their website</a>. All academic accommodations must be arranged through that
    office.</p>
  <h1 id="references" class="unnumbered">References</h1>
  <div id="refs" class="references">
    <div id="ref-archer_whats_2009">
      <p>Archer, Dawn, ed. <em>What’s in a Word-List?: Investigating Word Frequency and Keyword Extraction</em>.
        Ashgate, 2009.</p>
    </div>
    <div id="ref-arnold_humanities_2015">
      <p>Arnold, Taylor, and Lauren Tilton. <em>Humanities Data in R</em>. Springer, 2015. <a
          href="http://link.springer.com/10.1007/978-3-319-20702-5"
          class="uri">http://link.springer.com/10.1007/978-3-319-20702-5</a>.</p>
    </div>
    <div id="ref-binder_alien_2016">
      <p>Binder, Jeffrey M. “Alien Reading: Text Mining, Language Standardization, and the Humanities.” In <em>Debates
          in the Digital Humanities 2016</em>, edited by Matthew K. Gold and Lauren F. Klein, 201–17. University of
        Minnesota Press, 2016. <a href="http://dhdebates.gc.cuny.edu/debates/text/69"
          class="uri">http://dhdebates.gc.cuny.edu/debates/text/69</a>.</p>
    </div>
    <div id="ref-blevins_space_2014">
      <p>Blevins, Cameron. “Space, Nation, and the Triumph of Region: A View of the World from Houston.” <em>Journal of
          American History</em> 101, no. 1 (June 1, 2014): 122–147. doi:<a
          href="https://doi.org/10.1093/jahist/jau184">10.1093/jahist/jau184</a>.</p>
    </div>
    <div id="ref-bryan_happy_2016">
      <p>Bryan, Jenny. <em>Happy Git and GitHub for the useR</em>, 2016. <a href="http://happygitwithr.com/"
          class="uri">http://happygitwithr.com/</a>.</p>
    </div>
    <div id="ref-cohen_searching_2010">
      <p>Cohen, Dan. “Searching for the Victorians,” October 4, 2010. <a
          href="http://www.dancohen.org/2010/10/04/searching-for-the-victorians/"
          class="uri">http://www.dancohen.org/2010/10/04/searching-for-the-victorians/</a>.</p>
    </div>
    <div id="ref-cordell_reprinting_2015">
      <p>Cordell, Ryan. “Reprinting, Circulation, and the Network Author in Antebellum Newspapers.” <em>American
          Literary History</em> 27, no. 3 (September 1, 2015): 417–445. doi:<a
          href="https://doi.org/10.1093/alh/ajv028">10.1093/alh/ajv028</a>.</p>
    </div>
    <div id="ref-dalgaard_introductory_2008">
      <p>Dalgaard, Peter. <em>Introductory Statistics with R</em>. Statistics and Computing. Springer, 2008. <a
          href="http://link.springer.com/10.1007/978-0-387-79054-1"
          class="uri">http://link.springer.com/10.1007/978-0-387-79054-1</a>.</p>
    </div>
    <div id="ref-flanders_data_2016">
      <p>Flanders, Julia, and Fotis Jannidis. “Data Modeling.” In <em>A New Companion to the Digital Humanities</em>,
        edited by Susan Schreibman, Ray Siemens, and John Unsworth, 229–37. Wiley Blackwell, 2016.</p>
    </div>
    <div id="ref-fraas_mapping_2015">
      <p>Fraas, Mitch, and Benjamin Schmidt. “Mapping the State of the Union.” <em>The Atlantic</em> (January 18, 2015).
        <a href="http://www.theatlantic.com/politics/archive/2015/01/mapping-the-state-of-the-union/384576/"
          class="uri">http://www.theatlantic.com/politics/archive/2015/01/mapping-the-state-of-the-union/384576/</a>.
      </p>
    </div>
    <div id="ref-friedman_history_1985">
      <p>Friedman, Lawrence M. <em>A History of American Law</em>. 2nd ed. New York: Simon &amp; Schuster, 1985.</p>
    </div>
    <div id="ref-gavin_arithmetic_2015">
      <p>Gavin, Michael A. “The Arithmetic of Concepts: A Response to Peter de Bolla. Modeling Literary History,”
        September 18, 2015. <a
          href="http://modelingliteraryhistory.org/2015/09/18/the-arithmetic-of-concepts-a-response-to-peter-de-bolla/"
          class="uri">http://modelingliteraryhistory.org/2015/09/18/the-arithmetic-of-concepts-a-response-to-peter-de-bolla/</a>.
      </p>
    </div>
    <div id="ref-gold_forum:_2016">
      <p>Gold, Matthew K., Lauren F. Klein, Stephen Ramsay, Ted Underwood, Tanya E. Clement, Lisa Marie Rhody, Tressie
        McMillan Cottom, Benjamin M. Schmidt, Joanna Swafford, and Alan Liu. “Forum: Text Analysis at Scale.” In
        <em>Debates in the Digital Humanities 2016</em>, 525–568. University of Minnesota Press, 2016. <a
          href="http://dhdebates.gc.cuny.edu/debates/text/93"
          class="uri">http://dhdebates.gc.cuny.edu/debates/text/93</a>.</p>
    </div>
    <div id="ref-goldstone_quiet_2014">
      <p>Goldstone, Andrew, and Ted Underwood. “The Quiet Transformations of Literary Studies: What Thirteen Thousand
        Scholars Could Tell Us.” <em>New Literary History</em> 45, no. 3 (2014): 359–384. doi:<a
          href="https://doi.org/10.1353/nlh.2014.0025">10.1353/nlh.2014.0025</a>.</p>
    </div>
    <div id="ref-graham_exploring_2015">
      <p>Graham, Shawn, Ian Milligan, and Scott Weingart. <em>Exploring Big Historical Data: The Historian’s
          Macroscope</em>. Imperial College Press, 2015.</p>
    </div>
    <div id="ref-hitchcock_old_2016">
      <p>Hitchcock, Tim, and William J. Turkel. “The Old Bailey Proceedings, 1674–1913: Text Mining for Evidence of
        Court Behavior.” <em>Law and History Review</em> 34, no. 4 (August 2016): 1–27. doi:<a
          href="https://doi.org/10.1017/S0738248016000304">10.1017/S0738248016000304</a>.</p>
    </div>
    <div id="ref-hoeflich_legal_2010">
      <p>Hoeflich, Michael H. <em>Legal Publishing in Antebellum America</em>. New York: Cambridge University Press,
        2010.</p>
    </div>
    <div id="ref-james_introduction_2013">
      <p>James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. <em>An Introduction to Statistical
          Learning with Applications in R</em>. Springer, 2013.</p>
    </div>
    <div id="ref-jockers_macroanalysis:_2013">
      <p>Jockers, Matthew L. <em>Macroanalysis: Digital Methods and Literary History</em>. University of Illinois Press,
        2013.</p>
    </div>
    <div id="ref-jockers_text_2014">
      <p>———. <em>Text Analysis with R for Students of Literature</em>. Springer, 2014. <a
          href="http://link.springer.com/10.1007/978-3-319-03164-4"
          class="uri">http://link.springer.com/10.1007/978-3-319-03164-4</a>.</p>
    </div>
    <div id="ref-jockers_text-mining_2016">
      <p>Jockers, Matthew L., and Ted Underwood. “Text-Mining the Humanities.” In <em>A New Companion to the Digital
          Humanities</em>, edited by Susan Schreibman, Ray Siemens, and John Unsworth, 291–306. Wiley Blackwell, 2016.
      </p>
    </div>
    <div id="ref-knox_understanding_2013">
      <p>Knox, Doug. “Understanding Regular Expressions.” <em>Programming Historian</em> (June 22, 2013). <a
          href="http://programminghistorian.org/lessons/understanding-regular-expressions"
          class="uri">http://programminghistorian.org/lessons/understanding-regular-expressions</a>.</p>
    </div>
    <div id="ref-kuhn_applied_2013">
      <p>Kuhn, Max, and Kjell Johnson. <em>Applied Predictive Modeling</em>. Springer, 2013.</p>
    </div>
    <div id="ref-kusner_word_2015">
      <p>Kusner, Matt J., Yu Sun, Nicholas I. Kolkin, and Kilian Q. Weinberger. “From Word Embeddings to Document
        Distances.” In <em>Proceedings of the 32nd International Conference on Machine Learning (ICML 2015)</em>,
        957–966, 2015. <a href="http://www.jmlr.org/proceedings/papers/v37/kusnerb15.pdf"
          class="uri">http://www.jmlr.org/proceedings/papers/v37/kusnerb15.pdf</a>.</p>
    </div>
    <div id="ref-leskovec_mining_2014">
      <p>Leskovec, Jure, Anand Rajaraman, and Jeff Ullman. <em>Mining of Massive Datasets</em>. 2nd ed. Cambridge
        University Press, 2014. <a href="http://www.mmds.org/" class="uri">http://www.mmds.org/</a>.</p>
    </div>
    <div id="ref-michel_quantitative_2011">
      <p>Michel, Jean-Baptiste, Yuan Kui Shen, Aviva Presser Aiden, Adrian Veres, Matthew K. Gray, The Google Books
        Team, Joseph P. Pickett, et al. “Quantitative Analysis of Culture Using Millions of Digitized Books.”
        <em>Science</em> 331, no. 6014 (January 14, 2011): 176–182. doi:<a
          href="https://doi.org/10.1126/science.1199644">10.1126/science.1199644</a>.</p>
    </div>
    <div id="ref-mikolov_distributed_2013">
      <p>Mikolov, T., and J. Dean. “Distributed Representations of Words and Phrases and Their Compositionality.”
        <em>Advances in Neural Information Processing Systems</em> (2013). <a
          href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf"
          class="uri">https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf</a>.
      </p>
    </div>
    <div id="ref-milligan_automated_2012">
      <p>Milligan, Ian. “Automated Downloading with Wget.” <em>Programming Historian</em> (June 27, 2012). <a
          href="http://programminghistorian.org/lessons/automated-downloading-with-wget"
          class="uri">http://programminghistorian.org/lessons/automated-downloading-with-wget</a>.</p>
    </div>
    <div id="ref-moretti_distant_2013">
      <p>Moretti, Franco. <em>Distant Reading</em>. Verso, 2013.</p>
    </div>
    <div id="ref-moretti_graphs_2005">
      <p>———. <em>Graphs, Maps, Trees: Abstract Models for a Literary History</em>. Verso, 2005.</p>
    </div>
    <div id="ref-nelson_mining_2011">
      <p>Nelson, Robert K., and Digital Scholarship Lab, University of Richmond. “Mining the Dispatch,” 2011. <a
          href="http://dsl.richmond.edu/dispatch/" class="uri">http://dsl.richmond.edu/dispatch/</a>.</p>
    </div>
    <div id="ref-newman_probabilistic_2006">
      <p>Newman, David J., and Sharon Block. “Probabilistic Topic Decomposition of an Eighteenth-Century American
        Newspaper.” <em>Journal of the American Society for Information Science and Technology</em> 57, no. 6 (2006):
        753–767. <a href="http://onlinelibrary.wiley.com/doi/10.1002/asi.20342/full"
          class="uri">http://onlinelibrary.wiley.com/doi/10.1002/asi.20342/full</a>.</p>
    </div>
    <div id="ref-pennington_glove:_2014">
      <p>Pennington, Jeffrey, Richard Socher, and Christopher D. Manning. “Glove: Global Vectors for Word
        Representation.” In <em>EMNLP</em>, 14:1532–43, 2014. <a href="http://nlp.stanford.edu/pubs/glove.pdf"
          class="uri">http://nlp.stanford.edu/pubs/glove.pdf</a>.</p>
    </div>
    <div id="ref-ramsay_reading_2011">
      <p>Ramsay, Stephen. <em>Reading Machines: Toward an Algorithmic Criticism</em>. University of Illinois Press,
        2011.</p>
    </div>
    <div id="ref-robertson_searching_2016">
      <p>Robertson, Stephen. “Searching for Anglo-American Digital Legal History.” <em>Law and History Review</em> 34,
        no. 4 (August 2016). doi:<a href="https://doi.org/10.1017/S0738248016000389">10.1017/S0738248016000389</a>.</p>
    </div>
    <div id="ref-robertson_signs_1998">
      <p>———. “Signs, Marks, and Private Parts: Doctors, Legal Discourses, and Evidence of Rape in the United States,
        1823-1930.” <em>Journal of the History of Sexuality</em> 8, no. 3 (1998): 345–388. <a
          href="http://www.jstor.org/stable/3704870" class="uri">http://www.jstor.org/stable/3704870</a>.</p>
    </div>
    <div id="ref-robertson_differences_2016">
      <p>———. “The Differences Between Digital Humanities and Digital History.” In <em>Debates in the Digital Humanities
          2016</em>, edited by Matthew K. Gold and Lauren F. Klein, 289–307. University of Minnesota Press, 2016. <a
          href="http://dhdebates.gc.cuny.edu/debates/text/76"
          class="uri">http://dhdebates.gc.cuny.edu/debates/text/76</a>.</p>
    </div>
    <div id="ref-schmidt_age_2011">
      <p>Schmidt, Benjamin. “Age Cohort and Vocabulary Use. Sapping Attention,” April 11, 2011. <a
          href="http://sappingattention.blogspot.com/2011/04/age-cohort-and-vocabulary-use.html"
          class="uri">http://sappingattention.blogspot.com/2011/04/age-cohort-and-vocabulary-use.html</a>.</p>
    </div>
    <div id="ref-schmidt_rejecting_2015">
      <p>———. “Rejecting the Gender Binary: A Vector-Space Operation,” October 30, 2015. <a
          href="http://bookworm.benschmidt.org/posts/2015-10-30-rejecting-the-gender-binary.html"
          class="uri">http://bookworm.benschmidt.org/posts/2015-10-30-rejecting-the-gender-binary.html</a>.</p>
    </div>
    <div id="ref-schmidt_vector_2015">
      <p>———. “Vector Space Models for the Digital Humanities,” October 25, 2015. <a
          href="http://bookworm.benschmidt.org/posts/2015-10-25-Word-Embeddings.html"
          class="uri">http://bookworm.benschmidt.org/posts/2015-10-25-Word-Embeddings.html</a>.</p>
    </div>
    <div id="ref-schmidt_women_2012">
      <p>———. “Women in the Libraries. Sapping Attention,” May 8, 2012. <a
          href="http://sappingattention.blogspot.com/2012/05/women-in-libraries.html"
          class="uri">http://sappingattention.blogspot.com/2012/05/women-in-libraries.html</a>.</p>
    </div>
    <div id="ref-schmidt_language_2015">
      <p>Schmidt, Benjamin, and Mitch Fraas. “The Language of the State of the Union.” <em>The Atlantic</em> (January
        18, 2015). <a
          href="http://www.theatlantic.com/politics/archive/2015/01/the-language-of-the-state-of-the-union/384575/"
          class="uri">http://www.theatlantic.com/politics/archive/2015/01/the-language-of-the-state-of-the-union/384575/</a>.
      </p>
    </div>
    <div id="ref-sculley_meaning_2008">
      <p>Sculley, D., and Bradley M. Pasanek. “Meaning and Mining: The Impact of Implicit Assumptions in Data Mining for
        the Humanities.” <em>Literary and Linguistic Computing</em> 23, no. 4 (2008): 409–424. <a
          href="http://llc.oxfordjournals.org/content/23/4/409.short"
          class="uri">http://llc.oxfordjournals.org/content/23/4/409.short</a>.</p>
    </div>
    <div id="ref-shotts_linux_2016">
      <p>Shotts, William. <em>The Linux Command Line</em>. 3rd internet ed. No Starch Press, 2016. <a
          href="http://linuxcommand.org/tlcl.php" class="uri">http://linuxcommand.org/tlcl.php</a>.</p>
    </div>
    <div id="ref-silge_tidy_2016">
      <p>Silge, Julia, and David Robinson. <em>Tidy Text Mining in R</em>, 2016. <a href="http://tidytextmining.com/"
          class="uri">http://tidytextmining.com/</a>.</p>
    </div>
    <div id="ref-simpson_rise_1981">
      <p>Simpson, A. W. B. “The Rise and Fall of the Legal Treatise: Legal Principles and the Forms of Legal
        Literature.” <em>The University of Chicago Law Review</em> 48, no. 3 (1981): 632–679. doi:<a
          href="https://doi.org/10.2307/1599330">10.2307/1599330</a>.</p>
    </div>
    <div id="ref-sinclair_text_2016">
      <p>Sinclair, Stéfan, and Geoffrey Rockwell. “Text Analysis and Visualization: Making Meaning Count.” In <em>A New
          Companion to the Digital Humanities</em>, edited by Susan Schreibman, Ray Siemens, and John Unsworth, 274–90.
        Wiley Blackwell, 2016.</p>
    </div>
    <div id="ref-smith_computational_2015">
      <p>Smith, David A., Ryan Cordell, and Abby Mullen. “Computational Methods for Uncovering Reprinted Texts in
        Antebellum Newspapers.” <em>American Literary History</em> 27, no. 3 (September 1, 2015): E1–E15. doi:<a
          href="https://doi.org/10.1093/alh/ajv029">10.1093/alh/ajv029</a>.</p>
    </div>
    <div id="ref-smith_detecting_2014">
      <p>Smith, David A., Ryan Cordell, Elizabeth Maddock Dillon, Nick Stramp, and John Wilkerson. “Detecting and
        Modeling Local Text Reuse.” In <em>Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital
          Libraries</em>, 183–192. IEEE Press, 2014. <a href="http://dl.acm.org/citation.cfm?id=2740800"
          class="uri">http://dl.acm.org/citation.cfm?id=2740800</a>.</p>
    </div>
    <div id="ref-underwood_seven_2015">
      <p>Underwood, Ted. “Seven Ways Humanists Are Using Computers to Understand Text. The Stone and the Shell,” June 4,
        2015. <a href="https://tedunderwood.com/2015/06/04/seven-ways-humanists-are-using-computers-to-understand-text/"
          class="uri">https://tedunderwood.com/2015/06/04/seven-ways-humanists-are-using-computers-to-understand-text/</a>.
      </p>
    </div>
    <div id="ref-underwood_literary_2015">
      <p>———. “The Literary Uses of High-Dimensional Space.” <em>Big Data &amp; Society</em> 2, no. 2 (December 1,
        2015): 2053951715602494. doi:<a href="https://doi.org/10.1177/2053951715602494">10.1177/2053951715602494</a>.
      </p>
    </div>
    <div id="ref-underwood_theorizing_2014">
      <p>———. “Theorizing Research Practices We Forgot to Theorize Twenty Years Ago.” <em>Representations</em> 127, no.
        1 (August 1, 2014): 64–72. doi:<a
          href="https://doi.org/10.1525/rep.2014.127.1.64">10.1525/rep.2014.127.1.64</a>.</p>
    </div>
    <div id="ref-welke_law_2010">
      <p>Welke, Barbara Young. <em>Law and the Borders of Belonging in the Long Nineteenth Century United States</em>.
        Cambridge University Press, 2010.</p>
    </div>
    <div id="ref-wickham_advanced_2014">
      <p>Wickham, Hadley. <em>Advanced R</em>. Chapman; Hall, 2014. <a href="http://adv-r.had.co.nz/"
          class="uri">http://adv-r.had.co.nz/</a>.</p>
    </div>
    <div id="ref-wickham_r_2016">
      <p>Wickham, Hadley, and Garrett Grolemund. <em>R for Data Science</em>. O’Reilly, 2016. <a
          href="http://r4ds.had.co.nz/" class="uri">http://r4ds.had.co.nz/</a>.</p>
    </div>
    <div id="ref-witmore_text:_2012">
      <p>Witmore, Michael. “Text: A Massively Addressable Object.” In <em>Debates in the Digital Humanities 2012</em>.
        University of Minnesota Press, 2012. <a href="http://dhdebates.gc.cuny.edu/debates/text/28"
          class="uri">http://dhdebates.gc.cuny.edu/debates/text/28</a>.</p>
    </div>
    <div id="ref-xu_detecting_2014">
      <p>Xu, Shaobin, David A. Smith, Abigail Mullen, and Ryan Cordell. “Detecting and Evaluating Local Text Reuse in
        Social Networks.” <em>ACL 2014</em> (2014): 50. <a
          href="http://www.aclweb.org/website/old_anthology/W/W14/W14-27.pdf#page=62"
          class="uri">http://www.aclweb.org/website/old_anthology/W/W14/W14-27.pdf#page=62</a>.</p>
    </div>
  </div>

  <footer>
    This syllabus is copyright &copy; 2016 Lincoln Mullen. Licensed <a
      href="http://creativecommons.org/licenses/by/4.0/">CC-BY</a>.
  </footer>
</body>

</html>
